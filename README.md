# Language-Guided-Robotic-Object-Manipulation
system in which a robot uses natural language instructions to locate and manipulate objects. The visual pipeline would combine a segmentation model (e.g., Mask R-CNN or U-Net) for detecting and segmenting objects from a camera feed with a VLM like CLIP or BLIP to match language queries to segmented object features.
